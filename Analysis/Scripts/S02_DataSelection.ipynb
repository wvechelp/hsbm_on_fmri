{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15eb0edf",
   "metadata": {},
   "source": [
    "# Preparing RS-fMRI data for SBM analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6714b",
   "metadata": {},
   "source": [
    "This Python-notebook is the first step in the analysis of RS-fMRI data with hierarchical stochastic block models. It is part of the analyses underlying the dissertation \"Topic modelling for the stratification of neurological patients\" written by W. Van Echelpoel (WVE) under supervision of prof. D. Marinazzo (DM) (Ghent University). The data has been provided by DM and consisted of a folder structure that included the results of a 268 parcellation of RS-fMRI data (see further). \n",
    "\n",
    "The notebook has been developed to work with this specific data structure, but changes can be made to load different data sets (e.g., a 278 parcellation). Whenever the original data is not available, one can directly start with the (partially) pre-processed data (correlations between ROI-pairs). Visualisation of the conventional analyses is provided to get an insight, yet final graphs have been developed in R. For this, different scripts are available ('S03_SupervisedClustering.R')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35271c89",
   "metadata": {},
   "source": [
    "## Prepare environment with modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8722cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41945f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify working directory for data\n",
    "# os.getcwd() # To check working directory\n",
    "os.chdir(os.path.dirname(os.getcwd())) # Move out of 'Scripts'-folder\n",
    "os.chdir ('Data') # Move into 'Data'-folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820e7d3",
   "metadata": {},
   "source": [
    "## Data of 268 parcellation\n",
    "This section is only relevant if the original raw data is available. If this is not the case, one should move directly to the first subsection (contrasting means).\n",
    "\n",
    "As a first step, the data of the 268 parcellation is looked at. In this folder, there are 259 subfolders with data from participants (note that this number differs from the 'demo.csv' file, which mentions 260). Data is provided in individual matlab-files that have to be opened individually.\n",
    "\n",
    "For each participant, 152 measurements are provided for each of the 268 ROIs (although the length is 278, but the last 10 columns are empty). From this data, the Pearson coefficient between time series of different ROIs are calculated (thus increasing the number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with analysis of ROI of 268 parcellation (278: see further)\n",
    "os.chdir ('01 Raw Data') # Move into folder with raw data\n",
    "os.chdir ('ts268')\n",
    "os.chdir ('processed') # Only for ts268 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all participant folders\n",
    "folder_list = [f for f in os.listdir(os.getcwd()) if os.path.isdir(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to save all vectors, SD and correlations\n",
    "roiSTD = []\n",
    "corrList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe821f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all folders\n",
    "for folder in folder_list:\n",
    "    # Go deeper in folder list\n",
    "    os.chdir(folder)\n",
    "    os.chdir('fmri_rest')\n",
    "    \n",
    "    # Read in data + remove last 10 columns ('na')    \n",
    "    data_roi = scipy.io.loadmat(file_name = 'data_ROI_268')\n",
    "    data = [row[:268] for row in data_roi['data_ROI']]\n",
    "    \n",
    "    # Extract standard deviation of time series\n",
    "    roiSTD.append(list(pd.DataFrame(data).std()))\n",
    "    \n",
    "    # Pearson product-moment correlation coefficients\n",
    "    mx_correl = np.corrcoef(np.transpose(data))\n",
    "    \n",
    "    # Extract coefficients off-diagonal (here upper triangular part)\n",
    "    v_correl = mx_correl[np.triu_indices(len(mx_correl), k = 1)]\n",
    "    \n",
    "    # Append to list\n",
    "    corrList.append(v_correl)\n",
    "    \n",
    "    # Move up two folders to allow loop to continue\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Move three folders up to exit folder with raw data\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.dirname(os.getcwd())) # Move out of 'Scripts'-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e00375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference list for ROI-pairs\n",
    "df_roiRef, n_pair = [], 0\n",
    "for i in range(len(mx_correl)):\n",
    "    for j in range(i + 1, len(mx_correl)):\n",
    "        df_roiRef.append([i, j, 'Pair' + str(n_pair+1)])\n",
    "        n_pair += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f82ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roiRef = pd.DataFrame(df_roiRef, columns = ['Region 1', 'Region 2', 'Pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44166eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn correlation list into dataframe with indices\n",
    "corrList = pd.DataFrame(corrList, columns = ['Pair' + str(i+1) for i in range(len(corrList[0]))])\n",
    "corrList.index = folder_list\n",
    "\n",
    "# Turn STD list into dataframe with indices\n",
    "roiSTD = pd.DataFrame(roiSTD, columns = ['Pair' + str(i+1) for i in range(len(roiSTD[0]))])\n",
    "roiSTD.index = folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns (ROI-pairs) with missing data and exclude from data\n",
    "v_exclude = corrList.isnull().sum()[corrList.isnull().sum() > 0].index.tolist()\n",
    "corrList_NoNa = corrList.loc[:, ~corrList.columns.isin(v_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5880ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ROI-pairs to exclude to obtain a complete matrix\n",
    "len(v_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frames\n",
    "df_roiRef.to_csv('./02 Cleaned data/D_ROIReferenceList.txt', sep = ';')\n",
    "corrList.to_csv('./02 Cleaned data/D_PearsonCoefficient.txt', sep = ';')\n",
    "corrList_NoNa.to_csv('./02 Cleaned data/D_PearsonCoefficient_NoNa.txt', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26dd83",
   "metadata": {},
   "source": [
    "Aside from storing the data for subsequent analysis, it might be interesting to have a look at the data itself. For this, the main focus is directed at the Pearson coefficients (as per initial idea of the study). Attention is given to (1) contrast of the category means for all ROI-pairs, (2) PCA of the Pearson coefficient data, and (3) hierarchical clustering.\n",
    "\n",
    "The visualisation included in this notebook is meant to give an insight in the data and the results of the more conventional clustering techniques. The results of the category means are directly used by R for creating figures for the report, while PCA and hierarchical clustering are done anew in R (and the associated visual representations are used for the report). These steps are taken in the R-script 'S03_SupervisedClustering.R'. Hence, visualisations in this notebook are merely included for being a more stand-alone analysis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec7bbd",
   "metadata": {},
   "source": [
    "### Contrasting category means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c99d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data (if necessary), else update name\n",
    "corrDF = pd.read_csv('./02 Cleaned data/D_PearsonCoefficient_NoNa.txt', sep = \";\", index_col = 0)\n",
    "# corrDF = pd.DataFrame(corrList_NoNa)\n",
    "\n",
    "# Add column name with Group info\n",
    "corrDF = corrDF.assign(Category = [1]*120 + [2]*50 + [3]*49 + [4]*40)\n",
    "corrDF.iloc[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean Pearson coefficient per pair per category\n",
    "corrMeans = corrDF.groupby(['Category']).mean()\n",
    "corrMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2543172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pearson coefficient, from highest to lowest for category 1\n",
    "corrMeans.transpose().sort_values(by = 1,ascending = False).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba957916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean Pearson coefficients, as contrast between two groups (x and y can be changed)\n",
    "corrMeans.transpose().plot.scatter(x = 3, y = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data (e.g., for in R)\n",
    "corrMeans.to_csv('./02 Cleaned data/D_MeanPerCategory.txt', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0ac30",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a832a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data (if necessary), else update name\n",
    "# corrDF = pd.read_csv('./02 Cleaned data/D_PearsonCoefficient_NoNa.txt', sep = \";\", index_col = 0)\n",
    "corrDF = pd.DataFrame(corrList_NoNa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with 2 components\n",
    "pca_corr = PCA(n_components = 2)\n",
    "pcCorr = pca_corr.fit_transform(corrDF)\n",
    "pcCorr_Df = pd.DataFrame(data = pcCorr\n",
    "                         , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac11dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of RS-fMRI data of ROI coefficients\",fontsize=20)\n",
    "targets = ['HC', 'SCH', 'BD', 'ADHD']\n",
    "colors = ['r', 'g', 'y', 'b']\n",
    "plt.scatter(pcCorr_Df.loc[:120, 'principal component 1']\n",
    "                , pcCorr_Df.loc[:120, 'principal component 2'], c = 'r', s = 50)\n",
    "plt.scatter(pcCorr_Df.loc[121:170, 'principal component 1']\n",
    "                , pcCorr_Df.loc[121:170, 'principal component 2'], c = 'b', s = 50)\n",
    "plt.scatter(pcCorr_Df.loc[171:219, 'principal component 1']\n",
    "                , pcCorr_Df.loc[171:219, 'principal component 2'], c = 'y', s = 50)\n",
    "plt.scatter(pcCorr_Df.loc[220:, 'principal component 1']\n",
    "                , pcCorr_Df.loc[220:, 'principal component 2'], c = 'g', s = 50)\n",
    "    \n",
    "\n",
    "plt.legend(targets,prop={'size': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436eccf",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data (if necessary), else update name\n",
    "# corrDF = pd.read_csv('./02 Cleaned data/D_PearsonCoefficient_NoNa.txt', sep = \";\", index_col = 0)\n",
    "corrDF = pd.DataFrame(corrList_NoNa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate linkage with Euclidean distance\n",
    "linkage_data = linkage(corrDF, method='ward', metric='euclidean')\n",
    "dendrogram(linkage_data)\n",
    "\n",
    "# plt.rcParams['figure.dpi'] = 400 # To upgrade output graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine cluster membership, building on graph (3 clusters)\n",
    "v_cluster = fcluster(linkage_data, 3, criterion = 'maxclust')\n",
    "\n",
    "# Add information to dataframe\n",
    "corrDF = corrDF.assign(Category = [1]*120 + [2]*50 + [3]*49 + [4]*40, Cluster = v_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct crosstable to derive clustering\n",
    "pd.crosstab(index=corrDF['Category'], columns=corrDF['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3301cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data (e.g., for in R)\n",
    "corrDF.to_csv('./02 Cleaned data/D_HierarchicalClustering.txt', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663e054",
   "metadata": {},
   "source": [
    "### Selection of ROI-pairs based on correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e4d47",
   "metadata": {},
   "source": [
    "The original number of variables (i.e. ROI-pairs) is high and might affect subsequent parameter inference and overall interpretability. Hence, a reduction of the ROI-pairs is considered through a correlation analysis. Due to the long calculation time of a complete correlation matrix, an alternative approach was used. More specifically, correlated ROI-pairs with the first ROI-pair were identified and stored for later removal. Then, the same was done for the second ROI-pair (if it was not yet identified as having a correlation with the first ROI-pair) and so on. It is conceivable that a reorganisation of the ROI-pairs will result in a different selection of ROI-pairs to be removed, yet this has not been checked in the framework of this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data (if necessary), else update name\n",
    "# corrDF = pd.read_csv('./02 Cleaned data/D_PearsonCoefficient.txt', sep = \";\", index_col = 0)\n",
    "# corrDF_NoNa = pd.read_csv('./02 Cleaned data/D_PearsonCoefficient_NoNa.txt', sep = \";\", index_col = 0)\n",
    "corrDF = pd.DataFrame(corrList)\n",
    "corrDF_NoNa = pd.DataFrame(corrList_NoNa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold (MANUALLY!) and set for pairs to be eliminated\n",
    "n_lmt = [0.5, 0.75][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use column-wise approach to exclude pairs\n",
    "red = set()\n",
    "for p1 in range(corrDF.shape[1]):\n",
    "  print('--Column ' + str(p1 + 1) + ' of ' + str(corrDF.shape[1]) + '--')\n",
    "  for p2 in range(p1 + 1, corrDF.shape[1]):\n",
    "    if corrDF.columns[p1] not in red and corrDF.columns[p2] not in red:\n",
    "      n_corr = corrDF.iloc[:,p1].corr(corrDF.iloc[:,p2])\n",
    "      # print(corrDF.columns[p1] + ' & ' + corrDF.columns[p2] + ': ' + str(n_corr))\n",
    "      if abs(n_corr) > n_lmt:\n",
    "        red.add(corrDF.columns[p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use column-wise approach to exclude pairs\n",
    "red_NoNa = set()\n",
    "for p1 in range(corrDF_NoNa.shape[1]):\n",
    "  print('--Column ' + str(p1 + 1) + ' of ' + str(corrDF_NoNa.shape[1]) + '--')\n",
    "  for p2 in range(p1 + 1, corrDF_NoNa.shape[1]):\n",
    "    if corrDF_NoNa.columns[p1] not in red_NoNa and corrDF_NoNa.columns[p2] not in red_NoNa:\n",
    "      n_corr = corrDF_NoNa.iloc[:,p1].corr(corrDF_NoNa.iloc[:,p2])\n",
    "      # print(corrDF_NoNa.columns[p1] + ' & ' + corrDF_NoNa.columns[p2] + ': ' + str(n_corr))\n",
    "      if abs(n_corr) > n_lmt:\n",
    "        red_NoNa.add(corrDF_NoNa.columns[p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove (strongly) correlated pairs from dataframe\n",
    "corrSel = corrDF.drop(red, axis = 1)\n",
    "corrSel_NoNa = corrDF_NoNa.drop(red_NoNa, axis = 1)\n",
    "print('Start: ' + str(corrDF.shape) + ' - Reduced: ' + str(corrSel.shape))\n",
    "print('Start: ' + str(corrDF_NoNa.shape) + ' - Reduced: ' + str(corrSel_NoNa.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data (e.g., for in R)\n",
    "corrSel.to_csv('./02 Cleaned data/D_SelectedPairs_' + str(round(100*n_lmt)) + '.txt', sep = ';')\n",
    "corrSel_NoNa.to_csv('./02 Cleaned data/D_SelectedPairs_NoNa_' + str(round(100*n_lmt)) + '.txt', sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
